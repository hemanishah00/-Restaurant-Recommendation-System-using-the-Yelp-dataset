{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T15:03:21.257047Z","iopub.execute_input":"2022-02-16T15:03:21.257293Z","iopub.status.idle":"2022-02-16T15:03:21.270411Z","shell.execute_reply.started":"2022-02-16T15:03:21.257268Z","shell.execute_reply":"2022-02-16T15:03:21.269535Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/input/user-dataframe-for-yelp/user_df\n/kaggle/input/user-dataframe-for-yelp/__results__.html\n/kaggle/input/user-dataframe-for-yelp/__resultx__.html\n/kaggle/input/user-dataframe-for-yelp/__notebook__.ipynb\n/kaggle/input/user-dataframe-for-yelp/__output__.json\n/kaggle/input/user-dataframe-for-yelp/custom.css\n/kaggle/input/clean-review-hemani/clean_review.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing necessary libraries \nimport numpy as np\nimport pandas as pd\nimport matplotlib as plt\nimport tensorflow as tf\nimport seaborn as sns\nsns.set()\nimport json \nimport os\nimport csv\nimport json\nimport sqlite3\nfrom pathlib import Path\nfrom typing import Dict, Text\nfrom collections import defaultdict\n%matplotlib inline\nfrom scipy.sparse.linalg import svds\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:46:44.552275Z","iopub.execute_input":"2022-02-16T16:46:44.552570Z","iopub.status.idle":"2022-02-16T16:46:44.563746Z","shell.execute_reply.started":"2022-02-16T16:46:44.552539Z","shell.execute_reply":"2022-02-16T16:46:44.562661Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"# Importing our preprocessed review table\ncleaned_review = pd.read_pickle(\"../input/clean-review-hemani/clean_review.pkl\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:03:21.802614Z","iopub.execute_input":"2022-02-16T15:03:21.802884Z","iopub.status.idle":"2022-02-16T15:03:27.986977Z","shell.execute_reply.started":"2022-02-16T15:03:21.802848Z","shell.execute_reply":"2022-02-16T15:03:27.986482Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"#### The cleaned_review table contains only the business_ids of restraunts or places which serve food.</br>We have also droped all the columns except review_id, user_id, business_id and stars.","metadata":{}},{"cell_type":"code","source":"# Having a quick look at the cleaned review\ncleaned_review.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:03:27.989631Z","iopub.execute_input":"2022-02-16T15:03:27.989919Z","iopub.status.idle":"2022-02-16T15:03:28.001187Z","shell.execute_reply.started":"2022-02-16T15:03:27.989868Z","shell.execute_reply":"2022-02-16T15:03:28.000494Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                review_id                 user_id             business_id  \\\n0  lWC-xP3rd6obsecCYsGZRg  ak0TdVmGKo4pwqdJSTLwWw  buF9druCkbuXLX526sGELQ   \n1  hpcZLEzqD4_gPi6eSVi_Bg  Y-j2svl0M_5-jF1ehYuNPQ  buF9druCkbuXLX526sGELQ   \n2  3FvY1Se8y2WXqTbaANOqMw  xUCX4GhBpeWxZB0l2lmt_w  buF9druCkbuXLX526sGELQ   \n3  C1uQNP2ehBktS43ZRMEvkg  2M6KFsWIUXElqcQRz4A0Qg  buF9druCkbuXLX526sGELQ   \n4  Cja8_35_kQDnF9g4voikzw  t5SRIRU6INiAyVkiMJhRPA  buF9druCkbuXLX526sGELQ   \n\n   stars  \n0      4  \n1      2  \n2      5  \n3      5  \n4      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>lWC-xP3rd6obsecCYsGZRg</td>\n      <td>ak0TdVmGKo4pwqdJSTLwWw</td>\n      <td>buF9druCkbuXLX526sGELQ</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hpcZLEzqD4_gPi6eSVi_Bg</td>\n      <td>Y-j2svl0M_5-jF1ehYuNPQ</td>\n      <td>buF9druCkbuXLX526sGELQ</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3FvY1Se8y2WXqTbaANOqMw</td>\n      <td>xUCX4GhBpeWxZB0l2lmt_w</td>\n      <td>buF9druCkbuXLX526sGELQ</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>C1uQNP2ehBktS43ZRMEvkg</td>\n      <td>2M6KFsWIUXElqcQRz4A0Qg</td>\n      <td>buF9druCkbuXLX526sGELQ</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cja8_35_kQDnF9g4voikzw</td>\n      <td>t5SRIRU6INiAyVkiMJhRPA</td>\n      <td>buF9druCkbuXLX526sGELQ</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# create a dataframe grouped_by_userid which groups by the user_id and stores business_id, user_id and stars\ngrouped_by_userid = pd.DataFrame(cleaned_review.groupby('user_id')['business_id','user_id','stars'])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:03:28.002348Z","iopub.execute_input":"2022-02-16T15:03:28.002620Z","iopub.status.idle":"2022-02-16T15:04:33.040991Z","shell.execute_reply.started":"2022-02-16T15:03:28.002596Z","shell.execute_reply":"2022-02-16T15:04:33.040366Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"# having a quick look at the shape of the grouped_by_userid table\ngrouped_by_userid.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:04:33.042256Z","iopub.execute_input":"2022-02-16T15:04:33.042504Z","iopub.status.idle":"2022-02-16T15:04:33.047583Z","shell.execute_reply.started":"2022-02-16T15:04:33.042475Z","shell.execute_reply":"2022-02-16T15:04:33.046907Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"(1617955, 2)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### As we can see from the shape above there are 1617955 unique users","metadata":{}},{"cell_type":"code","source":"# having a quick look at a dataframe for one random user\ngrouped_by_userid[1][1066660]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:04:33.048318Z","iopub.execute_input":"2022-02-16T15:04:33.048480Z","iopub.status.idle":"2022-02-16T15:04:33.064741Z","shell.execute_reply.started":"2022-02-16T15:04:33.048459Z","shell.execute_reply":"2022-02-16T15:04:33.063971Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                      review_id                 user_id  \\\n658784   hvWVO9z7tl75by8bqUeUXA  eCBEtYYF2lJmgwF8f8Nbrw   \n3456223  xio4MPvQQGSAbAl9N2sY8A  eCBEtYYF2lJmgwF8f8Nbrw   \n5857585  aHR_6LtexhiGaoOi3iP4NA  eCBEtYYF2lJmgwF8f8Nbrw   \n\n                    business_id  stars  \n658784   zioLxtBc9THNS2TOn9xW1w      1  \n3456223  dowDBpVQVsbkBjEpVq62Zg      5  \n5857585  6GmUVd6ZD7L8weD5dV1g3Q      5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>658784</th>\n      <td>hvWVO9z7tl75by8bqUeUXA</td>\n      <td>eCBEtYYF2lJmgwF8f8Nbrw</td>\n      <td>zioLxtBc9THNS2TOn9xW1w</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3456223</th>\n      <td>xio4MPvQQGSAbAl9N2sY8A</td>\n      <td>eCBEtYYF2lJmgwF8f8Nbrw</td>\n      <td>dowDBpVQVsbkBjEpVq62Zg</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5857585</th>\n      <td>aHR_6LtexhiGaoOi3iP4NA</td>\n      <td>eCBEtYYF2lJmgwF8f8Nbrw</td>\n      <td>6GmUVd6ZD7L8weD5dV1g3Q</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### We tried to load the whole dataset in such a manner that the indexes consist of the business_ids and the columns consist of user_ids. This caused our RAM to crash multiple times.</br></br> We then decided to take a small sample of the data by picking the first 100 users and all the businesses in the review column. This caused increased sparsity, as there were many businesses which were not even rated once and were in the table.</br></br>Finally we decided to pick the first 1000 users which have given more than 100 reviews and created a table with only those users.</br>","metadata":{}},{"cell_type":"code","source":"# Creating a dictionary of all the users who have given more than 100 reviews. \n# We are doing this as an attempt to decrease sparsity\n# Creating an empty dictionary\ns = {}\n# looping through all the users\nfor i in range(1617955):\n    # creating a temporary variable user_1 which stores all the reviews given by a given user\n    user_1 = grouped_by_userid[1][i]\n    # creating a list of all review indexes for that particular user\n    idx = user_1.index\n    # if the user has given more than 100 reviews we add the no of reviews and the user index to the s dictionary\n    if len(idx)>100:\n        s[i] = len(idx)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:04:33.066022Z","iopub.execute_input":"2022-02-16T15:04:33.066421Z","iopub.status.idle":"2022-02-16T15:04:51.328010Z","shell.execute_reply.started":"2022-02-16T15:04:33.066384Z","shell.execute_reply":"2022-02-16T15:04:51.327429Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# creating a list which contains the userid and indexed according to the grouped_by_userid\nindex_userid = list(grouped_by_userid[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:04:51.329072Z","iopub.execute_input":"2022-02-16T15:04:51.329252Z","iopub.status.idle":"2022-02-16T15:04:51.690617Z","shell.execute_reply.started":"2022-02-16T15:04:51.329229Z","shell.execute_reply":"2022-02-16T15:04:51.690009Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"index_userid.index('-0eV_VL0_e0asdPv4u4EjQ')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:04:51.692691Z","iopub.execute_input":"2022-02-16T15:04:51.693378Z","iopub.status.idle":"2022-02-16T15:04:51.703865Z","shell.execute_reply.started":"2022-02-16T15:04:51.693349Z","shell.execute_reply":"2022-02-16T15:04:51.703334Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"666"},"metadata":{}}]},{"cell_type":"code","source":"# creating a list of all the users who have given reviews more than 100\nidx= list(s.keys())","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:07:09.007472Z","iopub.execute_input":"2022-02-16T15:07:09.008006Z","iopub.status.idle":"2022-02-16T15:07:09.012205Z","shell.execute_reply.started":"2022-02-16T15:07:09.007976Z","shell.execute_reply":"2022-02-16T15:07:09.011407Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Writing a function which adds all of a ratings for all the businesses rated by a particular user\ndef create1col(i):\n    user_1 = grouped_by_userid[1][i]\n    idx = user_1.index\n    x = pd.DataFrame(index = user_1['business_id'].unique(), columns=[user_1['user_id'][idx[0]]])\n    for i in idx:\n        x[user_1['user_id'][idx[0]]][user_1['business_id'][i]] = user_1['stars'][i]\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:07:11.548124Z","iopub.execute_input":"2022-02-16T15:07:11.548619Z","iopub.status.idle":"2022-02-16T15:07:11.555928Z","shell.execute_reply.started":"2022-02-16T15:07:11.548585Z","shell.execute_reply":"2022-02-16T15:07:11.555193Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# concatenating the first 2 users review tables using outer join\nx = pd.concat([create1col(idx[0]),create1col(idx[1])], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:07:48.230148Z","iopub.execute_input":"2022-02-16T15:07:48.230463Z","iopub.status.idle":"2022-02-16T15:07:48.266903Z","shell.execute_reply.started":"2022-02-16T15:07:48.230412Z","shell.execute_reply":"2022-02-16T15:07:48.266287Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# concatenating the dataframes for users which have the highest ratings\nfor i in idx[2:1000]:\n    x = pd.concat([x,create1col(i)], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:09:07.024998Z","iopub.execute_input":"2022-02-16T15:09:07.025597Z","iopub.status.idle":"2022-02-16T15:17:35.518502Z","shell.execute_reply.started":"2022-02-16T15:09:07.025566Z","shell.execute_reply":"2022-02-16T15:17:35.517320Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# creating a function which adds a particular user in the dataframe\ndef adduser(x,userid):\n    i = index_userid.index(userid)\n    if i not in idx:\n        x = pd.concat([x,create1col(i)], axis=1)\n    else:\n        print(\"user already in matrix\")\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:21:53.955768Z","iopub.execute_input":"2022-02-16T15:21:53.956500Z","iopub.status.idle":"2022-02-16T15:21:53.961483Z","shell.execute_reply.started":"2022-02-16T15:21:53.956431Z","shell.execute_reply":"2022-02-16T15:21:53.960985Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#Adding the user for whom we want to generate the recommendation\nitembased = adduser(x,'-5uvOHRkvijt1vzSX9RqzQ')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T16:21:01.351577Z","iopub.execute_input":"2022-02-16T16:21:01.352470Z","iopub.status.idle":"2022-02-16T16:21:01.490640Z","shell.execute_reply.started":"2022-02-16T16:21:01.352394Z","shell.execute_reply":"2022-02-16T16:21:01.489789Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"user already in matrix\n","output_type":"stream"}]},{"cell_type":"code","source":"# Finding the sparsity of the matrix\nsparsity = (itembased.isna().values.sum()/itembased.size)*100\nprint(\"The sparsity of the matrix is :\" + str(round(sparsity,2)) + \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:03:47.482369Z","iopub.execute_input":"2022-02-16T17:03:47.482658Z","iopub.status.idle":"2022-02-16T17:03:49.048331Z","shell.execute_reply.started":"2022-02-16T17:03:47.482627Z","shell.execute_reply":"2022-02-16T17:03:49.047891Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"The sparsity of the matrix is :99.58%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### We will now center the values around 0. We do this to handle sparsity of the matrix. We are doing this because we want to fill all the nan values with 0. If we don't center all our values around 0","metadata":{}},{"cell_type":"code","source":"# Centering the values around 0\n# Get the average rating for each user\navg_ratings = itembased.T.mean(axis=1)\n\n# Center each user's ratings around 0\nitem_ratings_table_centered = itembased.T.sub(avg_ratings, axis=0)\n\n# Fill in the missing data with 0s\nitem_ratings_table_normed = item_ratings_table_centered.fillna(0)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:03:52.190211Z","iopub.execute_input":"2022-02-16T17:03:52.190815Z","iopub.status.idle":"2022-02-16T17:04:21.364183Z","shell.execute_reply.started":"2022-02-16T17:03:52.190787Z","shell.execute_reply":"2022-02-16T17:04:21.363411Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"# Decompose the matrix \nU, sigma, Vt = svds(item_ratings_table_normed)\n# create a diagonal matrix with the sigma\nsigma = np.diag(sigma)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:04:21.365851Z","iopub.execute_input":"2022-02-16T17:04:21.366076Z","iopub.status.idle":"2022-02-16T17:04:24.966825Z","shell.execute_reply.started":"2022-02-16T17:04:21.366046Z","shell.execute_reply":"2022-02-16T17:04:24.966158Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"# Dot product of U and sigma\nU_sigma = np.dot(U, sigma)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:04:24.968537Z","iopub.execute_input":"2022-02-16T17:04:24.969777Z","iopub.status.idle":"2022-02-16T17:04:24.974921Z","shell.execute_reply.started":"2022-02-16T17:04:24.969741Z","shell.execute_reply":"2022-02-16T17:04:24.974334Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"# Dot product of result and Vt\nU_sigma_Vt = np.dot(U_sigma, Vt)\n\n# Add back on the row means contained in avg_ratings\nuncentered_ratings = U_sigma_Vt + avg_ratings.values.reshape(-1, 1)\n\n# Create DataFrame of the results\ncalc_pred_ratings_df = pd.DataFrame(uncentered_ratings, \n                                    index=itembased.T.index,\n                                    columns=itembased.T.columns\n                                   )","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:04:24.977585Z","iopub.execute_input":"2022-02-16T17:04:24.978887Z","iopub.status.idle":"2022-02-16T17:04:30.085031Z","shell.execute_reply.started":"2022-02-16T17:04:24.978849Z","shell.execute_reply":"2022-02-16T17:04:30.084282Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"# creating a function to recognize null values\ndef isNaN(num):\n    return num!= num","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:04:30.086057Z","iopub.execute_input":"2022-02-16T17:04:30.086228Z","iopub.status.idle":"2022-02-16T17:04:30.089696Z","shell.execute_reply.started":"2022-02-16T17:04:30.086205Z","shell.execute_reply":"2022-02-16T17:04:30.089009Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# Extract the actual values\nactual_values = itembased.T.values\n\n# Extract the predicted values\npredicted_values = calc_pred_ratings_df.values\n\n# Create a mask of actual_values to only look at the non-missing values in the ground truth\nmask = ~isNaN(actual_values)\n\n# Print the mean squared error between the actual values and the predicted values\nprint(mean_squared_error(actual_values[mask], predicted_values[mask]))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:04:30.090712Z","iopub.execute_input":"2022-02-16T17:04:30.090918Z","iopub.status.idle":"2022-02-16T17:04:34.633773Z","shell.execute_reply.started":"2022-02-16T17:04:30.090891Z","shell.execute_reply":"2022-02-16T17:04:34.632818Z"},"trusted":true},"execution_count":157,"outputs":[{"name":"stdout","text":"0.926576512089588\n","output_type":"stream"}]},{"cell_type":"code","source":"# importing itemname_itemid \nitemname_itemid = pd.read_pickle('../input/itemname-itemid/hemani.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:26:07.802124Z","iopub.execute_input":"2022-02-16T17:26:07.803043Z","iopub.status.idle":"2022-02-16T17:26:07.885196Z","shell.execute_reply.started":"2022-02-16T17:26:07.802997Z","shell.execute_reply":"2022-02-16T17:26:07.884716Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"# creating a function called recommendforuser which gives us top 5 suggestions for a user\ndef recommendforuser(userid):\n    m = calc_pred_ratings_df.loc[userid].sort_values(ascending=False)[:5]\n    item_1_ratings = pd.DataFrame(m).reset_index().rename(columns={'index':'business_id'})\n    item_1_ratings = item_1_ratings.merge(itemname_itemid,on='business_id',how='inner')\n    return item_1_ratings","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:26:19.056752Z","iopub.execute_input":"2022-02-16T17:26:19.057704Z","iopub.status.idle":"2022-02-16T17:26:19.062294Z","shell.execute_reply.started":"2022-02-16T17:26:19.057654Z","shell.execute_reply":"2022-02-16T17:26:19.061505Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"# calling the recommendforuser function for a particualr user\nrecommendforuser('-5uvOHRkvijt1vzSX9RqzQ')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:43:25.824590Z","iopub.execute_input":"2022-02-16T17:43:25.825334Z","iopub.status.idle":"2022-02-16T17:43:25.867945Z","shell.execute_reply.started":"2022-02-16T17:43:25.825267Z","shell.execute_reply":"2022-02-16T17:43:25.867236Z"},"trusted":true},"execution_count":194,"outputs":[{"execution_count":194,"output_type":"execute_result","data":{"text/plain":"              business_id  -5uvOHRkvijt1vzSX9RqzQ                       name\n0  I4jytmnWi2m9qGnuqNxUTg                3.333858         Sockeye City Grill\n1  243F-wnRuvt2ehf4RUDoeQ                3.333686                King Buffet\n2  TQj4HSCmm5GnriKMiSpqpQ                3.333663                      Raisu\n3  n1iC0j8DGAOfrkhQqxmSfA                3.333501                 McDonald's\n4  J3a6sldLoUpGlbco6JOmig                3.333466  California Hong Kong Cafe","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_id</th>\n      <th>-5uvOHRkvijt1vzSX9RqzQ</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I4jytmnWi2m9qGnuqNxUTg</td>\n      <td>3.333858</td>\n      <td>Sockeye City Grill</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>243F-wnRuvt2ehf4RUDoeQ</td>\n      <td>3.333686</td>\n      <td>King Buffet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TQj4HSCmm5GnriKMiSpqpQ</td>\n      <td>3.333663</td>\n      <td>Raisu</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n1iC0j8DGAOfrkhQqxmSfA</td>\n      <td>3.333501</td>\n      <td>McDonald's</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>J3a6sldLoUpGlbco6JOmig</td>\n      <td>3.333466</td>\n      <td>California Hong Kong Cafe</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}